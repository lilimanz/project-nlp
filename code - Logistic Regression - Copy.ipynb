{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      1  Cuando conocí a Janice en 2013 , una familia n...\n",
      "1      0  Hwang habló en Sur de este año por Southwest M...\n",
      "2      1  Usted podría pensar Katy Perry y Robert Pattin...\n",
      "3      1  Cualquiera que haya volado los cielos del crea...\n",
      "4      1  Bueno , este cantante tendrá un LARGO tiempo p...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Define the path to the text file\n",
    "file_path = 'TRAINING_DATA.txt'\n",
    "\n",
    "# Initialize lists to store labels and sentences\n",
    "labels = []\n",
    "sentences = []\n",
    "\n",
    "# Read the text file line by line\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Split each line into label and sentence using tab as the delimiter\n",
    "        label, sentence = line.strip().split('\\t')\n",
    "        labels.append(int(label))\n",
    "        sentences.append(sentence)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'label': labels, 'text': sentences})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cuando conocí a Janice en 2013 , una familia n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Hwang habló en Sur de este año por Southwest M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Usted podría pensar Katy Perry y Robert Pattin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cualquiera que haya volado los cielos del crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Bueno , este cantante tendrá un LARGO tiempo p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Cuando conocí a Janice en 2013 , una familia n...\n",
       "1      0  Hwang habló en Sur de este año por Southwest M...\n",
       "2      1  Usted podría pensar Katy Perry y Robert Pattin...\n",
       "3      1  Cualquiera que haya volado los cielos del crea...\n",
       "4      1  Bueno , este cantante tendrá un LARGO tiempo p..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Francesco\n",
      "[nltk_data]     Corda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Francesco\n",
      "[nltk_data]     Corda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw to C:\\Users\\Francesco\n",
      "[nltk_data]     Corda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    conocí janice 2013 familia necesitaba 600 punt...\n",
      "1    hwang habló sur año southwest music and media ...\n",
      "2    usted podría pensar katy perry robert pattinso...\n",
      "3    cualquiera volado cielos creador escuchado act...\n",
      "4    bueno cantante largo tiempo sentir aún remordi...\n",
      "Name: clean_blob, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "    # remove all single characters\n",
    "    text= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text) \n",
    "\n",
    "        \n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords.words('spanish')]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "data['clean_blob'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "print(data['clean_blob'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__C': 0.1, 'tfidf__max_features': 1000, 'tfidf__ngram_range': (1, 1)}\n",
      "Best cross-validation score: 0.48304267909650644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['clean_blob'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a pipeline combining the TfidfVectorizer and LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000, 2000, 5000, 10000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # You can also test different n-gram ranges\n",
    "    'clf__C': [0.1, 1, 10]  # Regularization parameter for Logistic Regression\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best cross-validation score:\", best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__C': 0.1, 'vectorizer__max_features': 2000, 'vectorizer__ngram_range': (1, 1)}\n",
      "Best cross-validation score: 0.4672399987289886\n"
     ]
    }
   ],
   "source": [
    "# with countclassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['clean_blob'], data['label'], test_size=0.2, random_state=42, stratify=data['label'])\n",
    "\n",
    "# Define a pipeline combining the CountVectorizer and LogisticRegression\n",
    "pipeline_CV = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid_CV = {\n",
    "    'vectorizer__max_features': [2000, 5000, 10000],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__C': [0.1, 1, 10]  # Regularization parameter for Logistic Regression\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with stratified k-fold cross-validation\n",
    "grid_search_CV = GridSearchCV(pipeline_CV, param_grid_CV, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_CV.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding score\n",
    "best_params_CV = grid_search_CV.best_params_\n",
    "best_score_CV = grid_search_CV.best_score_\n",
    "\n",
    "print(\"Best parameters:\", best_params_CV)\n",
    "print(\"Best cross-validation score:\", best_score_CV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression with TFDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer with the optimal number of features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=best_params['tfidf__max_features'], ngram_range=best_params['tfidf__ngram_range'])\n",
    "\n",
    "# Transform the processed text\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "\n",
    "# Initialize and train the Logistic Regression model with the best regularization parameter\n",
    "model = LogisticRegression(C=best_params['clf__C'])\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val_tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47315436241610737\n",
      "Precision: 0.4842498665242926\n",
      "Recall: 0.496986301369863\n",
      "F1 Score: 0.4905354245538129\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45805369127516776\n",
      "Precision: 0.46113989637305697\n",
      "Recall: 0.49776286353467564\n",
      "F1 Score: 0.47875201721355565\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "y_pred = grid_search_CV.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_CV = accuracy_score(y_val, y_pred)\n",
    "precision_CV = precision_score(y_val, y_pred)\n",
    "recall_CV = recall_score(y_val, y_pred)\n",
    "f1_CV = f1_score(y_val, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy_CV}')\n",
    "print(f'Precision: {precision_CV}')\n",
    "print(f'Recall: {recall_CV}')\n",
    "print(f'F1 Score: {f1_CV}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
